---
title: Assistants
desc: How can I help?
---
I've been preparing my final presentation for my research this summer (the work continues, of course), and it's offered me a few opportunities to consider the social dynamics interacting with bots. Obviously, most of my mental energy these days is toward technical and design concerns, and when I start drifting in my head I can spend hours musing about the [philosophical implications of technological progress]({% post_url 2014-07-12-mornings %}). But figuring out how to present this work more broadly has gotten me thinking about the more immediate effects/implications/whatever about what we're building.

The name of the main bot project that Gordon's lab has worked on for the last few years is "Athena," after the Greek goddess of wisdom, since it's designed as a way to access information from scholarly databases (they've now expanded to Wikipedia and web sources, so it's become quite useful—would definitely recommend giving it a go). But when after I had been in the lab for a bit, Gordon was excited enough about my work and ideas about domain generalization, that he set me up with a new team that's working on a fork off of Athena called "Gina" (for generalization), with less focus on information retrieval, more focus on natural language and figuring out how to generalize from a domain-specific bot, etc.

And as I was putting together my poster for presenting, I realized how little thought was put into the name. Gina. I don't even remember whose idea it was; Gordon just told me we would be working on this new project—maybe it was his name, maybe one of the grad students came up with it. And this is all sensible in a way, because really the name shouldn't matter that much and we are all rightfully more engaged with the technical challenges and ideas we're dealing with.

But then again, if we start to think outside the bubble of academia and into the real world, I think things like names do matter. Anyway, this morning as I made tea, I absentmindedly asked one of the grad students on my team—more a rhetorical musing than anything—why we had decided to give the bot a feminine name. This guy is generally a really bright, lovely person, but his response was just so much to deal with: "This might sound sexist, but I think people expect virtual assistants to be female because generally human assistants are female. Whether this is a good or bad thing, it's what people are familiar with, so it's the default."

I didn't really respond to this, because I just didn't know how. To be honest, I think his reasoning is probably pretty on point to some extent. But so much of his matter-of-fact attitude and the way he answered the question just felt so off to me. Firstly, if you're sentence starts with "This might sound sexist, but …" that might be a good sign you should spend a bit longer reflecting on it so you can maybe challenge that sexism and reformulate your thought. Have you thought about why most "assistants" (whatever that broad term means) are female—what history is behind that? And then also this uncritical idea about "defaults" and what people are familiar with: we work in a human computer interaction lab! Isn't our whole purpose to change how people engage with technology? We're building technology in Silicon Valley! Isn't our whole purpose to disrupt things?

But oddly the thing that stuck with me most about what he said, when I was thinking back over the moment throughout the day, and especially when I was meditating just now (I didn't do the best job of not fixating on the thoughts), even more than the idea of the bot's gender, was this word, "assistant." I guess it's been used before in the lab, especially with regards to Athena. But I don't think I've really thought about Gina as an assistant. Nevertheless, that language—"virtual assistant"—is so pervasive right now. Sure, these pieces of software exist to help people out, but especially as they get more sophisticated, shouldn't we consider that lots of people other than "assistants" add value to our lives? Teachers, mentors, parents, siblings, friends … To tie back to gender, I guess, it seems so oddly *male* to require a computer personality to hold a lower status than one's self. To be an *assistant*. If only for variety, I'm more interested in thinking about what a virtual *mentor* would be like.

Maybe the words don't mean much in themselves though. After all, I and all the grad students I work with are technically research *assistants*, and that doesn't keep us from doing sophisticated research and playing complex roles on the team. And the name is a small thing (Athena is even a name of power, actually, which feels paradoxical); Gina communicates over text, and I think gender is probably more significant when there's a voice attached, like for Siri or whatever Microsoft's new version of Siri is.

Which reminds me: A while ago, I was chatting with the one other woman on our team about the proliferation of virtual assistants on smartphones. When I asked what she thought about the fact that they all had feminine voices, she gave a pretty sensible answer: "Well, there's certainly no shortage of male voices trying to explain things to me."
